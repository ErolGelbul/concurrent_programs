{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Thread pools, Map/Reduce, Data races\n",
    "## February 18th\n",
    "\n",
    "We have seen the use of Fork/Join pools and map/reduce algorithms in the lecture. The tutorial gave a little additional depth on race conditions. In today's practical, we will revisit these concepts and look at how they are implemented in Python.\n",
    "\n",
    "We will again be using Python's `threading` module. It provides all the tools that are needed to implement thread pools and Map/Reduce-style concurrent computation. Moreover, we will analyse how we can use the process synchronisation tools that we have learned about in the last two sessions to avoid race conditions when processing data in parallel. \n",
    "\n",
    "## Learning outcomes\n",
    "1. Using `ThreadPools` in Python\n",
    "2. Implement and run a simple Map/Reduce algorithm\n",
    "2. Understanding and resolving race conditions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Thread pools \n",
    "We'll start of using thread and process pools in Python. The relevant classes are contained in `multiprocessing.pool`, a sub-module of the `multiprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing.pool as mpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instatiate a `ThreadPool` with 4 threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_4 = mpp.ThreadPool(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we distribute a couple of tasks across the `ThreadPool` and have them executed concurrently. We start off simple, so let's implement a friendly function `say_hi` that is going to be executed in the threads. It simply prints the name of the thread that is executing it. As seen previously, we included a tiny wait time before the print statement to simulate what might happen on a busy system when, i.e. when threads get interleaved. \n",
    "\n",
    "Please put your name in the `args` parameter to be greeted properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def say_hi(name):\n",
    "    time.sleep(random.random() * 0.3) # wait for a little while to force interleaving\n",
    "    print(\"Hi {} from thread {}\".format(name, threading.current_thread().name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll submit the function to the `ThreadPool` for execution to be executed 10 times. We use the `apply_async` method for this purpose, calling it 10 times in a loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi PM from thread Thread-14\n",
      "Hi PM from thread Thread-11\n",
      "Hi PM from thread Thread-14Hi PM from thread Thread-13\n",
      "\n",
      "Hi PM from thread Thread-14\n",
      "Hi PM from thread Thread-12\n",
      "Hi PM from thread Thread-13\n",
      "Hi PM from thread Thread-11\n",
      "Hi PM from thread Thread-12Hi PM from thread Thread-14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_statements = 10\n",
    "\n",
    "for i in range(num_statements):\n",
    "    tp_4.apply_async(func=say_hi, args=('PM',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is that all four threads say \"Hi\" a couple of times. Please note that the `Thread` that executes the message is always one of the four threads in the `ThreadPool`.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## Exercise 1\n",
    "The `apply_async` method works *asynchronously*, which means that it doesn't wait for the submitted function to return. The `ThreadPool` also has an `apply` function that blocks until the submitted function returns. What effect on concurrent execution do you expect?\n",
    "\n",
    "Change the `apply_async` to `apply` and run the example again. Compare the time the cell takes to complete between the two versions. What do you observe?\n",
    "<br/><hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Map/Reduce\n",
    "Many interesting problems in computing involve splitting work across many workers and combining their individual results afterwards. This is often called _Divide and Conquer_, or, more recently, _Map/Reduce_. The Map/Reduce pattern essentially involves two steps:\n",
    "\n",
    "1. __Map:__ assign functions and chunks of data to individual worker threads.\n",
    "2. __Reduce:__ Combine the results from the worker threads. \n",
    "\n",
    "### 3.2.1 Map\n",
    "Let's have a loook at the `map` function in the `ThreadPool` class first. We'll use the `say_hi` function from above but this time we'll use it to greet many different people instead of just one person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Nicholas from thread Thread-5\n",
      "Hi Erica from thread Thread-5\n",
      "Hi Bradley from thread Thread-6\n",
      "Hi Sachin from thread Thread-4\n",
      "Hi Christopher from thread Thread-6\n",
      "Hi Prijanka from thread Thread-7\n",
      "Hi Lyubomir from thread Thread-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['Bradley', 'Sachin', 'Prijanka', 'Nicholas', 'Erica', 'Lyubomir', 'Christopher']\n",
    "\n",
    "tp_4.map(say_hi, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `map` method takes a function and a list of arguments, and executes the function once for each argument. Since we use a `ThreadPool`, the function/argument pairs are evenly distributed across all threads in the pool.\n",
    "\n",
    "The difference to the `apply_async` function is that we don't need a loop to distribute the function; the `map` function takes care of this for us. \n",
    "\n",
    "You may have noted the line that goes \"``` [None, None, None, None, None, None, None] ```\". This signifies that the `map` method returned a list of values. Each of the values is the return value of one of the instances of our `say_hi` function. Since this function doesn't return anything, the return value is `None`. \n",
    "\n",
    "And this leads us directly to... \n",
    "\n",
    "### 3.2.2 Reduce\n",
    "\n",
    "The _reduce_ step is all about combining the results from the _mapped_ functions. Since our `say_hi` function was more of a toy that didn't compute or return anything, we're going to need another function that does a bit of actual work. \n",
    "\n",
    "Say we want to sum up all numbers in a large array. Using the map/reduce paradigm, we can simply split the array across multiple workers (Map) and sum up the result afterwards (Reduce).\n",
    "\n",
    "First, let's create a long list of numbers and split this into equal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The split list has 11 smaller lists, they have element counts [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 4].\n"
     ]
    }
   ],
   "source": [
    "num_items = 1005\n",
    "long_list = list(range(1, num_items)) #array with numbers from 1 to num_items - 1\n",
    "\n",
    "num_splits = 10 # the number of splits we want to use\n",
    "split_length = 100\n",
    "\n",
    "split_list = []\n",
    "for i in range(0, len(long_list), split_length):\n",
    "    split_list.append(long_list[i:i + split_length])\n",
    "\n",
    "\n",
    "print(\"The split list has {} smaller lists, they have element counts {}.\".format(len(split_list), [len(li) for li in split_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a function that sums all elements in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(the_list):\n",
    "    the_sum = 0\n",
    "    for i in range(len(the_list)):\n",
    "        the_sum += the_list[i]\n",
    "    return(the_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's __map__ this function with the split list on the `ThreadPool`. This time we store the individual results in the `result` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tp_4.map(sum, split_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5050, 15050, 25050, 35050, 45050, 55050, 65050, 75050, 85050, 95050, 4010]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we __reduce__ the list of individual results to produce the final result. To this end we use Python's `reduce` function. This takes two parameters: a function that specifies how to combine __two__ results, and the list that is to be reduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final sum from the multithreaded version is 504510.\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def sum_two(x, y):\n",
    "    return x + y\n",
    "\n",
    "final_sum = reduce(sum_two, result)\n",
    "\n",
    "print(\"The final sum from the multithreaded version is {}.\".format(final_sum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, let's see if we get the same result when we use our `sum` function to sum the whole list, without splitting it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final sum from the singlethreaded version is 504510.\n",
      "Both results are the same.\n"
     ]
    }
   ],
   "source": [
    "final_sum_singlethread = sum(long_list)\n",
    "print(\"The final sum from the singlethreaded version is {}.\".format(final_sum))\n",
    "\n",
    "if (final_sum == final_sum_singlethread):\n",
    "    print(\"Both results are the same.\")\n",
    "else:\n",
    "    print(\"Oh no! The results differ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, `reduce` is usually used with Python's `lambda` function. Python `lambda` functions allow you to define 'anonymous' functions in-place, that is, functions without a name at the location in the code where they are actually used. Using `lambda`, our example looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final sum from the multithreaded version is 504510.\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "#def sum_two(x, y):\n",
    "#    return x + y\n",
    "\n",
    "# note how the lambda definition replaces the previous sum_two function:\n",
    "final_sum = reduce(lambda x,y: x+y, result)\n",
    "\n",
    "print(\"The final sum from the multithreaded version is {}.\".format(final_sum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Exercise 2 (a tricky one if you like a challenge)\n",
    "\n",
    "Which three single characters need to be changed in the code above in order to compute the *product* of all number in the list? \n",
    "<br/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Race conditions\n",
    "\n",
    "Race conditions are always potential hazards when working with concurrent access to data. In the above Map/Reduce example, we avoided race conditions by splitting data into distinct chunks that are then separately processed by concurrent workers. Only in the final reduce step the data is combined in a non-concurrent fashion. \n",
    "\n",
    "But sometimes we need to access data concurrently in order to achieve the desired result. \n",
    "\n",
    "Consider the following function. It takes a `global` variable that is shared across threads and counts it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_em_down(count):\n",
    "    global number\n",
    "    for i in range(count):\n",
    "        number -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each thread shall count down a fraction of the `global` number, so that in the end the `global` number will be at zero. \n",
    "\n",
    "We'll use the `apply_async` method to invoke this function concurrently on a number of threads. Since `apply_async` doesn't block, we need to make sure that we wait until all computation is finished. This is achieved by the last `for`-loop, where we call `wait()` on the individual results from the threads.\n",
    "\n",
    "(if you want to know how exactly this works please look up the documentation of [Process Pools in the Python docs](https://docs.python.org/3/library/multiprocessing.html?highlight=multiprocessing#module-multiprocessing.pool)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 10\n",
    "count = 100000\n",
    "number = num_threads * count\n",
    "results = []\n",
    "for i in range(num_threads):\n",
    "    result = tp_4.apply_async(count_em_down, args=(count,))\n",
    "    results.append(result)\n",
    "\n",
    "for r in results:\n",
    "    r.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number should be 0. Actually, it is 262352.\n"
     ]
    }
   ],
   "source": [
    "print(\"Number should be 0. Actually, it is {}.\".format(number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "The number should be 0, but it is something considerable higher than that. How can this happen? Think about a timing diagram that could explain this. \n",
    "<br/>\n",
    "<hr/>\n",
    "\n",
    "## Exercise 4 (a coding exercise, finally!!!)\n",
    "Fix the race condition by using `threading.Lock`. Hint: You should define the `Lock` outside the `count_em_down` function, but you should `acquire` and `release` the lock in the function.\n",
    "<br/>\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading as th \n",
    "count_sema = th.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_em_down1(count, sema):\n",
    "    global number\n",
    "    \n",
    "    for i in range(count):\n",
    "        sema.acquire()\n",
    "        number -= 1\n",
    "        sema.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number initially is 1000000.\n"
     ]
    }
   ],
   "source": [
    "num_threads = 10\n",
    "count = 100000\n",
    "number = num_threads * count\n",
    "print(\"Number initially is {}.\".format(number))\n",
    "results = []\n",
    "for i in range(num_threads):\n",
    "    result = tp_4.apply_async(count_em_down1, args=(count,count_sema))\n",
    "    results.append(result)\n",
    "\n",
    "for r in results:\n",
    "    r.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number should be 0. Actually, it is 0.\n"
     ]
    }
   ],
   "source": [
    "print(\"Number should be 0. Actually, it is {}.\".format(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
